{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimización usando gradiente descendente - Regresión polinomial\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "En este laboratio se estimarán los parámetros óptimos de un modelo de regresión \n",
    "polinomial de grado `n`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def pregunta_01():\n",
    "    \"\"\"\n",
    "    Complete el código presentado a continuación.\n",
    "    \"\"\"\n",
    "    # Importe pandas\n",
    "    import pandas as pd\n",
    "\n",
    "    # Importe PolynomialFeatures\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    # Cargue el dataset `data.csv`\n",
    "    data = pd.read_csv('data.csv')    \n",
    "    \n",
    "    # Cree un objeto de tipo `PolynomialFeatures` con grado `2`\n",
    "    poly = PolynomialFeatures(2)\n",
    "\n",
    "    # Transforme la columna `x` del dataset `data` usando el objeto `poly`\n",
    "    x_poly = poly.fit_transform(data[[\"x\"]])\n",
    "\n",
    "    # Retorne x y y\n",
    "    return x_poly, data.y\n",
    "\n",
    "\n",
    "def pregunta_02():\n",
    "\n",
    "    # Importe numpy\n",
    "    import numpy as np\n",
    "\n",
    "    x_poly, y = pregunta_01()\n",
    "\n",
    "    # Fije la tasa de aprendizaje en 0.0001 y el número de iteraciones en 1000\n",
    "    learning_rate = 0.0001\n",
    "    n_iterations = 1000\n",
    "\n",
    "    # Defina el parámetro inicial `params` como un arreglo de tamaño 3 con ceros\n",
    "    params = np.zeros(x_poly.shape[1])\n",
    "    for _ in range(n_iterations):\n",
    "\n",
    "        # Compute el pronóstico con los parámetros actuales\n",
    "        y_pred = np.sum(np.multiply(x_poly, params), axis = 1)\n",
    "\n",
    "        # Calcule el error (MSE)\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Calcule el gradiente\n",
    "        a_derivative = sum(x_poly[:, 2] * (error))\n",
    "        b_derivative = sum(x_poly[:, 1] * (error))\n",
    "        c_derivative = sum(x_poly[:, 0] * (error))\n",
    "        \n",
    "        gradient = np.array([c_derivative, b_derivative, a_derivative])\n",
    "        \n",
    "        # Actualice los parámetros\n",
    "        params = params - learning_rate * gradient\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe numpy\n",
    "import numpy as np\n",
    "\n",
    "x_poly, y = pregunta_01()\n",
    "\n",
    "# Fije la tasa de aprendizaje en 0.0001 y el número de iteraciones en 1000\n",
    "learning_rate = 0.0001\n",
    "n_iterations = 1000\n",
    "\n",
    "# Defina el parámetro inicial `params` como un arreglo de tamaño 3 con ceros\n",
    "params = np.zeros(x_poly.shape[1])\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    '''\n",
    "    # Compute el pronóstico con los parámetros actuales\n",
    "    y_pred = np.sum(np.multiply(x_poly, params), axis = 1)\n",
    "\n",
    "    n = len(y)\n",
    "\n",
    "    # Calcule el error (MSE)\n",
    "    error = np.sum((y-y_pred)**2) / n\n",
    "\n",
    "    # Calcule el gradiente\n",
    "    a_derivative = -(2/n) * sum(x_poly[:, 2] * (y - y_pred))\n",
    "    b_derivative = -(2/n) * sum(x_poly[:, 1] * (y - y_pred))\n",
    "    c_derivative = -(2/n) * sum(x_poly[:, 0] * (y - y_pred))\n",
    "\n",
    "    gradient = np.array([c_derivative, b_derivative, a_derivative])\n",
    "\n",
    "    # Actualice los parámetros\n",
    "    params = params - learning_rate * gradient\n",
    "    '''\n",
    "    \n",
    "    # Compute el pronóstico con los parámetros actuales\n",
    "    y_pred = np.sum(np.multiply(x_poly, params), axis = 1)\n",
    "\n",
    "    # Calcule el error\n",
    "    error = y_pred - y\n",
    "\n",
    "    # Calcule el gradiente\n",
    "    \n",
    "    a_derivative = sum(x_poly[:, 2] * (error))\n",
    "    b_derivative = sum(x_poly[:, 1] * (error))\n",
    "    c_derivative = sum(x_poly[:, 0] * (error))\n",
    "\n",
    "    gradient_2 = np.array([c_derivative, b_derivative, a_derivative])\n",
    "    \n",
    "    #gradient = np.dot(x_poly.T, error)\n",
    "\n",
    "    # Actualice los parámetros\n",
    "    params = params - learning_rate * gradient_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6664678 , -2.99999557,  2.03178244])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calificación del laboratorio\n",
    "-----------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def test_01():\n",
    "    \"\"\"\n",
    "    ---< Run command >-------------------------------------------------------------------\n",
    "    Pregunta 01\n",
    "    pip3 install scikit-learn pandas numpy\n",
    "    python3 tests.py 01\n",
    "    \"\"\"\n",
    "\n",
    "    x_poly, _ = pregunta_01()\n",
    "    x_poly = x_poly.round(3)\n",
    "    x_expected = np.array(\n",
    "        [\n",
    "            [1.0, -4.0, 16.0],\n",
    "            [1.0, -3.579, 12.809],\n",
    "            [1.0, -3.158, 9.972],\n",
    "            [1.0, -2.737, 7.49],\n",
    "            [1.0, -2.316, 5.363],\n",
    "            [1.0, -1.895, 3.59],\n",
    "            [1.0, -1.474, 2.172],\n",
    "            [1.0, -1.053, 1.108],\n",
    "            [1.0, -0.632, 0.399],\n",
    "            [1.0, -0.21, 0.044],\n",
    "            [1.0, 0.21, 0.044],\n",
    "            [1.0, 0.632, 0.399],\n",
    "            [1.0, 1.053, 1.108],\n",
    "            [1.0, 1.474, 2.172],\n",
    "            [1.0, 1.895, 3.59],\n",
    "            [1.0, 2.316, 5.363],\n",
    "            [1.0, 2.737, 7.49],\n",
    "            [1.0, 3.158, 9.972],\n",
    "            [1.0, 3.579, 12.809],\n",
    "            [1.0, 4.0, 16.0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for i in range(x_poly.shape[0]):\n",
    "        for j in range(x_poly.shape[1]):\n",
    "            assert x_poly[i, j] == x_expected[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_02():\n",
    "    \"\"\"\n",
    "    ---< Run command >-------------------------------------------------------------------\n",
    "    Pregunta 02\n",
    "    pip3 install scikit-learn pandas numpy\n",
    "    python3 tests.py 02\n",
    "    \"\"\"\n",
    "    params = pregunta_02()\n",
    "    expected = np.array([0.666, -3.0, 2.032])\n",
    "    assert np.allclose(params, expected, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 14],\n",
       "       [ 1,  3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[4, 1], [1, 0]]\n",
    "b = [[1, 3], [0, 2]]\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  9, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_derivative = sum(m[:, 2] * e)\n",
    "b_derivative = sum(m[:, 1] * e)\n",
    "c_derivative = sum(m[:, 0] * e)\n",
    "\n",
    "gradient_2 = np.array([c_derivative, b_derivative, a_derivative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
